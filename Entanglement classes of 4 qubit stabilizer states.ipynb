{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec874a05-b1e9-4eed-900e-6e41a8447bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\capture\\capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.4.33 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import itertools\n",
    "import scipy.stats\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info import random_clifford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aebb351-1532-4800-954e-09f5bb1c4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24 24 24 24\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "dev1 = qml.device(\"default.qubit\", wires=n_qubits)  #no edges\n",
    "dev2 = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev3 = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev4 = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev5 = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "dev6 = qml.device(\"default.qubit\", wires=n_qubits) \n",
    "\n",
    "base_edges2 = [(0, 1)]\n",
    "base_edges3 = [(0, 1), (2, 3)]\n",
    "base_edges4 = [(0, 1), (0, 2)]\n",
    "base_edges5 = [(0, 1), (0,2), (2,3)]\n",
    "base_edges6 = [(0, 1), (0,2), (0,3)]\n",
    "\n",
    "# All 24 permutations of [0, 1, 2, 3]\n",
    "permutations = list(itertools.permutations(range(n_qubits)))\n",
    "\n",
    "@qml.qnode(dev1)\n",
    "def run_permuted_graph_state1(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    return qml.state()\n",
    "\n",
    "@qml.qnode(dev2)\n",
    "def run_permuted_graph_state2(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    for (a, b) in base_edges2:\n",
    "        qa = permutation[a]\n",
    "        qb = permutation[b]\n",
    "        qml.CZ(wires=[qa, qb])\n",
    "    return qml.state()\n",
    "\n",
    "@qml.qnode(dev3)\n",
    "def run_permuted_graph_state3(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    for (a, b) in base_edges3:\n",
    "        qa = permutation[a]\n",
    "        qb = permutation[b]\n",
    "        qml.CZ(wires=[qa, qb])\n",
    "    return qml.state()\n",
    "\n",
    "@qml.qnode(dev4)\n",
    "def run_permuted_graph_state4(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    for (a, b) in base_edges4:\n",
    "        qa = permutation[a]\n",
    "        qb = permutation[b]\n",
    "        qml.CZ(wires=[qa, qb])\n",
    "    return qml.state()\n",
    "\n",
    "@qml.qnode(dev5)\n",
    "def run_permuted_graph_state5(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    for (a, b) in base_edges5:\n",
    "        qa = permutation[a]\n",
    "        qb = permutation[b]\n",
    "        qml.CZ(wires=[qa, qb])\n",
    "    return qml.state()\n",
    "\n",
    "@qml.qnode(dev6)\n",
    "def run_permuted_graph_state6(permutation):\n",
    "    for q in permutation:\n",
    "        qml.Hadamard(wires=q)\n",
    "    for (a, b) in base_edges6:\n",
    "        qa = permutation[a]\n",
    "        qb = permutation[b]\n",
    "        qml.CZ(wires=[qa, qb])\n",
    "    return qml.state()\n",
    "\n",
    "states1 = []\n",
    "for perm in permutations:\n",
    "    state1 = run_permuted_graph_state1(perm)\n",
    "    states1.append(state1)\n",
    "states1 = np.array(states1, dtype=np.complex64)\n",
    "\n",
    "states2 = []\n",
    "for perm in permutations:\n",
    "    state2 = run_permuted_graph_state2(perm)\n",
    "    states2.append(state2)\n",
    "states2 = np.array(states2, dtype=np.complex64)\n",
    "\n",
    "states3 = []\n",
    "for perm in permutations:\n",
    "    state3 = run_permuted_graph_state3(perm)\n",
    "    states3.append(state3)\n",
    "states3 = np.array(states3, dtype=np.complex64)\n",
    "\n",
    "states4 = []\n",
    "for perm in permutations:\n",
    "    state4 = run_permuted_graph_state4(perm)\n",
    "    states4.append(state4)\n",
    "states4 = np.array(states4, dtype=np.complex64)\n",
    "\n",
    "states5 = []\n",
    "for perm in permutations:\n",
    "    state5 = run_permuted_graph_state5(perm)\n",
    "    states5.append(state5)\n",
    "states5 = np.array(states5, dtype=np.complex64)\n",
    "\n",
    "states6 = []\n",
    "for perm in permutations:\n",
    "    state6 = run_permuted_graph_state6(perm)\n",
    "    states6.append(state6)\n",
    "states6 = np.array(states6, dtype=np.complex64)\n",
    "print(len(states1), len(states2), len(states3), len(states4), len(states5), len(states6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ab0330-1568-4349-9bcd-e6749fb618af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuantumStateDataset(states1, states2, states3, states4, states5, states6, num_samples=70):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        \n",
    "        for i in range(24):\n",
    "            matrix1, matrix2, matrix3, matrix4 = random_clifford_unitary(1), random_clifford_unitary(1), random_clifford_unitary(1), random_clifford_unitary(1)\n",
    "            combined_matrix_in1 = np.kron(matrix1, matrix2)\n",
    "            combined_matrix_in2 = np.kron(combined_matrix_in1, matrix3)\n",
    "            combined_matrix = np.kron(combined_matrix_in2, matrix4)\n",
    "            first_state = states1[i]    # Class no. 1\n",
    "            second_state = states2[i]   # Class no. 2\n",
    "            third_state = states3[i]    # Class no. 3\n",
    "            fourth_state = states4[i]   # Class no. 4\n",
    "            fifth_state = states5[i]    # Class no. 5\n",
    "            sixth_state = states6[i]    # Class no. 6\n",
    "       \n",
    "            zero_label_states = [( first_state, 0)]\n",
    "            one_label_states = [( fourth_state, 1), ( sixth_state , 1), (second_state , 1), (fifth_state  , 1), (third_state, 1)]\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                initial_state, label = random.choice(zero_label_states)\n",
    "            else:\n",
    "                initial_state, label = random.choice(one_label_states)\n",
    "                \n",
    "            resulting_state = np.dot(combined_matrix, initial_state)\n",
    "            norm = np.linalg.norm(resulting_state)\n",
    "            normalized_resulting_state = resulting_state / norm\n",
    "            data.append(normalized_resulting_state)\n",
    "            labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "def random_clifford_unitary(n, seed=None, su2=False):\n",
    "    \"\"\"Uniformly sample an n-qubit Clifford and return its unitary matrix.\"\"\"\n",
    "    C = random_clifford(n, seed=seed)   \n",
    "    U_np = C.to_matrix()   \n",
    "    U = torch.as_tensor(U_np, dtype=torch.complex64)\n",
    "    return U\n",
    "\n",
    "class QuantumStateTorchDataset(Dataset):\n",
    "    def __init__(self, states, labels):\n",
    "        # Convert complex input to real and imaginary parts\n",
    "        self.states = torch.tensor(states, dtype=torch.complex64)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.labels[idx]\n",
    "\n",
    "class RealOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, qlayer):\n",
    "        super().__init__()\n",
    "        self.qlayer = qlayer\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_out = self.qlayer(x)\n",
    "        return q_out.real \n",
    "\n",
    "def accuracy(X, Y):\n",
    "    predictions = torch.sign(X)\n",
    "    acc = ((predictions+Y)**2)/4\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5774abd9-ae79-4129-ae22-eb038a022f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "def variational_circuit(weights, inputs):\n",
    "    qml.templates.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize=True)\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3))]\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_model(weights, inputs):\n",
    "    return variational_circuit(weights, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3499ac96-87d0-4512-9738-15f6570b39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 16) (4800, 16) (4800, 1) (4800, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_o, y_train_o = QuantumStateDataset(states1, states2, states3, states4, states5, states6, num_samples=200)\n",
    "X_test_o, y_test_o = QuantumStateDataset(states1, states2, states3, states4, states5, states6, num_samples=200)\n",
    "\n",
    "X_train= np.array(X_train_o)\n",
    "y_train = np.array(y_train_o)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test= np.array(X_test_o)\n",
    "y_test = np.array(y_test_o)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "y_train = y_train * 2 - 1  \n",
    "y_test = y_test * 2 - 1\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c5260d-8590-4409-85de-5ab9ea6ddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "lr=0.001\n",
    "weight_shapes = {\"weights\": (num_layers, n_qubits, 3)}\n",
    "num_epochs = 300\n",
    "batch_size = 10\n",
    "batches = (X_train.shape[0]) // batch_size\n",
    "batches_test = (X_test.shape[0]) // batch_size\n",
    "\n",
    "train_dataset = QuantumStateTorchDataset(X_train, y_train)\n",
    "test_dataset = QuantumStateTorchDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "193e2488-af6d-48a4-93c4-41dfa7f4730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlayer = qml.qnn.TorchLayer(quantum_model, weight_shapes)\n",
    "clayer1 = torch.nn.Linear(4, 400)\n",
    "clayer2 = torch.nn.Linear(400, 50)\n",
    "clayer3 = torch.nn.Linear(50, 1)\n",
    "tanh = torch.nn.Tanh()\n",
    "model = torch.nn.Sequential(RealOutputWrapper(qlayer) , clayer1, tanh, clayer2, tanh, clayer3, tanh)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a7a01b-a68d-4e9d-9b51-7bf5b5369600",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = []\n",
    "loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "train_auc_list=[]\n",
    "test_auc_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4b9953-b5e3-428e-81db-b661fcab92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss over epoch 1: 1.0244\n",
      "Average loss over epoch 2: 1.0021\n",
      "Average loss over epoch 3: 0.9466\n",
      "Average loss over epoch 4: 0.4541\n",
      "Average loss over epoch 5: 0.2662\n",
      "Average loss over epoch 6: 0.2599\n",
      "Average loss over epoch 7: 0.2549\n",
      "Average loss over epoch 8: 0.2446\n",
      "Average loss over epoch 9: 0.2347\n",
      "Average loss over epoch 10: 0.2313\n",
      "Average loss over epoch 11: 0.2243\n",
      "Average loss over epoch 12: 0.2170\n",
      "Average loss over epoch 13: 0.2121\n",
      "Average loss over epoch 14: 0.2109\n",
      "Average loss over epoch 15: 0.2073\n",
      "Average loss over epoch 16: 0.2038\n",
      "Average loss over epoch 17: 0.1970\n",
      "Average loss over epoch 18: 0.1947\n",
      "Average loss over epoch 19: 0.1889\n",
      "Average loss over epoch 20: 0.1848\n",
      "Average loss over epoch 21: 0.1839\n",
      "Average loss over epoch 22: 0.1793\n",
      "Average loss over epoch 23: 0.1699\n",
      "Average loss over epoch 24: 0.1725\n",
      "Average loss over epoch 25: 0.1717\n",
      "Average loss over epoch 26: 0.1682\n",
      "Average loss over epoch 27: 0.1680\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(model(x).shape)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print(y.shape)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(model(x).dtype)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(y.dtype)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m loss_evaluated \u001b[38;5;241m=\u001b[39m loss(model(x), y)\n\u001b[0;32m     12\u001b[0m loss_evaluated\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     14\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 59\u001b[0m, in \u001b[0;36mRealOutputWrapper.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     q_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqlayer(x)\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_out\u001b[38;5;241m.\u001b[39mreal\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\qnn\\torch.py:404\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    401\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[1;32m--> 404\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_qnode(inputs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\qnn\\torch.py:430\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m    429\u001b[0m }\n\u001b[1;32m--> 430\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:882\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_capture_qnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m capture_qnode  \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:850\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_impl_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m qml\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mResult:\n\u001b[0;32m    848\u001b[0m \n\u001b[0;32m    849\u001b[0m     \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m     tape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(args, kwargs)\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "File \u001b[1;32mC:\\Users\\Public\\New folder\\envs\\QML\\Lib\\site-packages\\pennylane\\logging\\decorators.py:61\u001b[0m, in \u001b[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m     s_caller \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::L\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     55\u001b[0m         [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetouterframes(inspect\u001b[38;5;241m.\u001b[39mcurrentframe(), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]]\n\u001b[0;32m     56\u001b[0m     )\n\u001b[0;32m     57\u001b[0m     lgr\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_caller\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_debug_log_kwargs,\n\u001b[0;32m     60\u001b[0m     )\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        opt.zero_grad()\n",
    "        #print(model(x).shape)\n",
    "        #print(y.shape)\n",
    "        # print(model(x).dtype)\n",
    "        # print(y.dtype)\n",
    "        loss_evaluated = loss(model(x), y)\n",
    "        loss_evaluated.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss_evaluated\n",
    "\n",
    "    avg_loss = running_loss / batches\n",
    "    loss_list.append(avg_loss.item())\n",
    "    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00d2852-7e09-40c2-90f8-d9d346cad712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f922a1-5197-49a7-b691-b58949d597b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for training dataset tensor(0.1613, grad_fn=<DivBackward0>)\n",
      "Accuracy for training dataset tensor(0.9542, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "running_loss=0\n",
    "for x, y in train_loader:\n",
    "        loss_evaluated = loss(model(x), y)\n",
    "        running_loss += loss_evaluated\n",
    "avg_loss = running_loss / batches\n",
    "print(\"Average loss for training dataset\",avg_loss)\n",
    "\n",
    "running_acc=0\n",
    "for x, y in train_loader:\n",
    "        acc_evaluated = accuracy(model(x), y)\n",
    "        running_acc += torch.mean(acc_evaluated) \n",
    "avg_acc = running_acc / batches\n",
    "print(\"Accuracy for training dataset\", avg_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682fa63d-68d6-4462-a0d3-7a29378d09bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "Average loss for test dataset tensor(0.1754, grad_fn=<DivBackward0>)\n",
      "Accuracy for test dataset tensor(0.9494, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "running_loss_test=0\n",
    "for x, y in test_loader:\n",
    "        loss_evaluated_test = loss(model(x), y)\n",
    "        running_loss_test += loss_evaluated_test\n",
    "avg_loss_test = running_loss_test / batches_test\n",
    "print(batches_test)\n",
    "print(\"Average loss for test dataset\", avg_loss_test)\n",
    "\n",
    "running_acc_test=0\n",
    "for x, y in test_loader:\n",
    "        acc_evaluated_test = accuracy(model(x), y)\n",
    "        running_acc_test += torch.mean(acc_evaluated_test)\n",
    "avg_acc_test = running_acc_test / batches_test\n",
    "print(\"Accuracy for test dataset\",avg_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3424d52-7438-4328-9a0b-7c78850e5322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
